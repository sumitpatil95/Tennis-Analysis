{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis Action Recognition - Data Exploration\n",
    "\n",
    "This notebook explores the tennis action recognition dataset with COCO format annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "from src.data.dataset_processor import TennisDatasetProcessor\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset processor\n",
    "processor = TennisDatasetProcessor(\"../data/tennis_dataset\")\n",
    "\n",
    "# Load and process dataset\n",
    "annotation_files = [\"tennis_actions.json\"]  # Replace with your actual annotation files\n",
    "df = processor.process_dataset(annotation_files)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Action Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action distribution\n",
    "action_counts = df['action_name'].value_counts()\n",
    "print(\"Action distribution:\")\n",
    "print(action_counts)\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "action_counts.plot(kind='bar', color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "plt.title('Distribution of Tennis Actions', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Action Type', fontsize=12)\n",
    "plt.ylabel('Number of Images', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keypoint Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze keypoint statistics\n",
    "keypoint_stats = df['num_keypoints'].describe()\n",
    "print(\"Keypoint statistics:\")\n",
    "print(keypoint_stats)\n",
    "\n",
    "# Plot keypoint distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "df['num_keypoints'].hist(bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Number of Keypoints', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Number of Keypoints', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keypoint Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_keypoints(image_path, keypoints, action_name):\n",
    "    \"\"\"Visualize keypoints on image\"\"\"\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Reshape keypoints\n",
    "    kpts = keypoints.reshape(-1, 2)\n",
    "    \n",
    "    # Denormalize keypoints\n",
    "    h, w = image.shape[:2]\n",
    "    kpts[:, 0] *= w\n",
    "    kpts[:, 1] *= h\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    # Draw keypoints\n",
    "    for i, (x, y) in enumerate(kpts):\n",
    "        if x > 0 and y > 0:  # Only draw visible keypoints\n",
    "            plt.plot(x, y, 'ro', markersize=8)\n",
    "            plt.text(x+5, y-5, processor.keypoint_names[i], fontsize=8, color='white', \n",
    "                    bbox=dict(boxstyle='round,pad=0.2', facecolor='red', alpha=0.7))\n",
    "    \n",
    "    plt.title(f'Tennis Action: {action_name}', fontsize=16, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sample images for each action\n",
    "for action in df['action_name'].unique():\n",
    "    sample = df[df['action_name'] == action].iloc[0]\n",
    "    if Path(sample['image_path']).exists():\n",
    "        visualize_keypoints(sample['image_path'], sample['keypoints'], action)\n",
    "    else:\n",
    "        print(f\"Image not found for {action}: {sample['image_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for analysis\n",
    "X, y = processor.extract_features_for_classical_ml(df)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"Feature names: Keypoints (36) + Engineered features (6) = {X.shape[1]} total\")\n",
    "\n",
    "# Analyze feature distributions by action\n",
    "feature_df = pd.DataFrame(X)\n",
    "feature_df['action'] = y\n",
    "\n",
    "# Plot some key features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Hand distance (feature 36)\n",
    "axes[0, 0].boxplot([feature_df[feature_df['action'] == i][36].values for i in range(4)])\n",
    "axes[0, 0].set_title('Hand Distance by Action')\n",
    "axes[0, 0].set_xticklabels(processor.action_categories.values())\n",
    "\n",
    "# Shoulder distance (feature 37)\n",
    "axes[0, 1].boxplot([feature_df[feature_df['action'] == i][37].values for i in range(4)])\n",
    "axes[0, 1].set_title('Shoulder Distance by Action')\n",
    "axes[0, 1].set_xticklabels(processor.action_categories.values())\n",
    "\n",
    "# Left arm angle (feature 38)\n",
    "axes[1, 0].boxplot([feature_df[feature_df['action'] == i][38].values for i in range(4)])\n",
    "axes[1, 0].set_title('Left Arm Angle by Action')\n",
    "axes[1, 0].set_xticklabels(processor.action_categories.values())\n",
    "\n",
    "# Right arm angle (feature 39)\n",
    "axes[1, 1].boxplot([feature_df[feature_df['action'] == i][39].values for i in range(4)])\n",
    "axes[1, 1].set_title('Right Arm Angle by Action')\n",
    "axes[1, 1].set_xticklabels(processor.action_categories.values())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing or invalid data\n",
    "print(\"Data Quality Assessment:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Missing image paths: {df['image_path'].isna().sum()}\")\n",
    "print(f\"Missing keypoints: {df['keypoints'].isna().sum()}\")\n",
    "print(f\"Invalid keypoint shapes: {sum(kp.shape != (36,) for kp in df['keypoints'])}\")\n",
    "\n",
    "# Check image accessibility\n",
    "missing_images = 0\n",
    "for img_path in df['image_path']:\n",
    "    if not Path(img_path).exists():\n",
    "        missing_images += 1\n",
    "\n",
    "print(f\"Missing image files: {missing_images}\")\n",
    "print(f\"Data completeness: {((len(df) - missing_images) / len(df)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train/Validation/Test Split Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data splits\n",
    "train_df, val_df, test_df = processor.create_train_val_test_split(df)\n",
    "\n",
    "# Analyze splits\n",
    "splits_info = {\n",
    "    'Train': train_df,\n",
    "    'Validation': val_df,\n",
    "    'Test': test_df\n",
    "}\n",
    "\n",
    "# Plot split distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, (split_name, split_df) in enumerate(splits_info.items()):\n",
    "    action_counts = split_df['action_name'].value_counts()\n",
    "    action_counts.plot(kind='bar', ax=axes[idx], color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "    axes[idx].set_title(f'{split_name} Set\\n({len(split_df)} samples)', fontweight='bold')\n",
    "    axes[idx].set_xlabel('Action Type')\n",
    "    axes[idx].set_ylabel('Count')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed split information\n",
    "print(\"\\nDetailed Split Information:\")\n",
    "for split_name, split_df in splits_info.items():\n",
    "    print(f\"\\n{split_name} Set:\")\n",
    "    print(f\"  Total samples: {len(split_df)}\")\n",
    "    print(f\"  Action distribution:\")\n",
    "    for action, count in split_df['action_name'].value_counts().items():\n",
    "        percentage = (count / len(split_df)) * 100\n",
    "        print(f\"    {action}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "output_dir = \"../data/processed\"\n",
    "processor.save_processed_data(train_df, val_df, test_df, output_dir)\n",
    "\n",
    "print(f\"Processed data saved to {output_dir}\")\n",
    "print(\"Files created:\")\n",
    "print(\"  - train_data.pkl\")\n",
    "print(\"  - val_data.pkl\")\n",
    "print(\"  - test_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provided a comprehensive exploration of the tennis action recognition dataset:\n",
    "\n",
    "1. **Dataset Overview**: Loaded and processed COCO format annotations\n",
    "2. **Action Distribution**: Analyzed the balance of different tennis actions\n",
    "3. **Keypoint Analysis**: Examined keypoint quality and completeness\n",
    "4. **Feature Engineering**: Created additional features from keypoint data\n",
    "5. **Data Quality**: Assessed data completeness and validity\n",
    "6. **Data Splits**: Created stratified train/validation/test splits\n",
    "7. **Data Export**: Saved processed data for model training\n",
    "\n",
    "The dataset appears to be well-balanced with 500 images per action class, and the keypoint annotations provide rich information for action recognition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}