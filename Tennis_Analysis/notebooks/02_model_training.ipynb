{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis Action Recognition - Model Training\n",
    "\n",
    "This notebook trains and evaluates both classical ML and deep learning models for tennis action recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.data.dataset_processor import TennisDatasetProcessor\n",
    "from src.models.classical_ml import ClassicalMLTrainer\n",
    "from src.models.deep_learning import DeepLearningTrainer, KeypointMLP, HybridCNN\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "data_dir = \"../data/processed\"\n",
    "\n",
    "train_df = pd.read_pickle(f\"{data_dir}/train_data.pkl\")\n",
    "val_df = pd.read_pickle(f\"{data_dir}/val_data.pkl\")\n",
    "test_df = pd.read_pickle(f\"{data_dir}/test_data.pkl\")\n",
    "\n",
    "print(f\"Train set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(val_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "\n",
    "# Initialize processor for feature extraction\n",
    "processor = TennisDatasetProcessor(\"../data/tennis_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classical Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for classical ML\n",
    "print(\"Extracting features for classical ML...\")\n",
    "X_train, y_train = processor.extract_features_for_classical_ml(train_df)\n",
    "X_val, y_val = processor.extract_features_for_classical_ml(val_df)\n",
    "X_test, y_test = processor.extract_features_for_classical_ml(test_df)\n",
    "\n",
    "print(f\"Feature shape: {X_train.shape}\")\n",
    "print(f\"Classes: {np.unique(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classical ML trainer\n",
    "classical_trainer = ClassicalMLTrainer()\n",
    "\n",
    "# Prepare data (scaling)\n",
    "X_train_scaled, X_val_scaled, X_test_scaled = classical_trainer.prepare_data(X_train, X_val, X_test)\n",
    "\n",
    "print(\"Data prepared and scaled for classical ML models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "rf_model = classical_trainer.train_random_forest(X_train_scaled, y_train, X_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM\n",
    "svm_model = classical_trainer.train_svm(X_train_scaled, y_train, X_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "lr_model = classical_trainer.train_logistic_regression(X_train_scaled, y_train, X_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN\n",
    "knn_model = classical_trainer.train_knn(X_train_scaled, y_train, X_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Evaluate Classical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all classical models\n",
    "classical_results = classical_trainer.evaluate_models(X_test_scaled, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n=== Classical ML Results ===\")\n",
    "for model_name, results in classical_results.items():\n",
    "    print(f\"\\n{model_name.upper()}:\")\n",
    "    print(f\"  Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"  F1 (macro): {results['f1_macro']:.4f}\")\n",
    "    print(f\"  F1 (weighted): {results['f1_weighted']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "classical_trainer.plot_confusion_matrices(classical_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model comparison\n",
    "classical_trainer.plot_model_comparison(classical_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize deep learning trainer\n",
    "dl_trainer = DeepLearningTrainer()\n",
    "\n",
    "print(f\"Using device: {dl_trainer.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Keypoint MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for MLP (keypoints only)\n",
    "train_loader_mlp, val_loader_mlp, test_loader_mlp = dl_trainer.create_data_loaders(\n",
    "    train_df, val_df, test_df, batch_size=32, keypoints_only=True\n",
    ")\n",
    "\n",
    "print(f\"MLP Data loaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader_mlp)}\")\n",
    "print(f\"  Val batches: {len(val_loader_mlp)}\")\n",
    "print(f\"  Test batches: {len(test_loader_mlp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP model\n",
    "mlp_model = KeypointMLP(input_dim=36, hidden_dims=[512, 256, 128], num_classes=4)\n",
    "trained_mlp = dl_trainer.train_model(\n",
    "    mlp_model, train_loader_mlp, val_loader_mlp, \n",
    "    'keypoint_mlp', num_epochs=50, learning_rate=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MLP training history\n",
    "dl_trainer.plot_training_history('keypoint_mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Hybrid CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for CNN (images + keypoints)\n",
    "train_loader_cnn, val_loader_cnn, test_loader_cnn = dl_trainer.create_data_loaders(\n",
    "    train_df, val_df, test_df, batch_size=16, keypoints_only=False\n",
    ")\n",
    "\n",
    "print(f\"CNN Data loaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader_cnn)}\")\n",
    "print(f\"  Val batches: {len(val_loader_cnn)}\")\n",
    "print(f\"  Test batches: {len(test_loader_cnn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Hybrid CNN model\n",
    "cnn_model = HybridCNN(num_classes=4, keypoint_dim=36)\n",
    "trained_cnn = dl_trainer.train_model(\n",
    "    cnn_model, train_loader_cnn, val_loader_cnn,\n",
    "    'hybrid_cnn', num_epochs=50, learning_rate=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CNN training history\n",
    "dl_trainer.plot_training_history('hybrid_cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MLP model\n",
    "mlp_results = dl_trainer.evaluate_model(trained_mlp, test_loader_mlp, 'keypoint_mlp')\n",
    "\n",
    "# Evaluate CNN model\n",
    "cnn_results = dl_trainer.evaluate_model(trained_cnn, test_loader_cnn, 'hybrid_cnn')\n",
    "\n",
    "print(\"\\n=== Deep Learning Results ===\")\n",
    "print(f\"\\nKEYPOINT MLP:\")\n",
    "print(f\"  Accuracy: {mlp_results['accuracy']:.4f}\")\n",
    "print(f\"  F1 (macro): {mlp_results['f1_macro']:.4f}\")\n",
    "print(f\"  F1 (weighted): {mlp_results['f1_weighted']:.4f}\")\n",
    "\n",
    "print(f\"\\nHYBRID CNN:\")\n",
    "print(f\"  Accuracy: {cnn_results['accuracy']:.4f}\")\n",
    "print(f\"  F1 (macro): {cnn_results['f1_macro']:.4f}\")\n",
    "print(f\"  F1 (weighted): {cnn_results['f1_weighted']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results for comparison\n",
    "all_results = {\n",
    "    **classical_results,\n",
    "    'keypoint_mlp': mlp_results,\n",
    "    'hybrid_cnn': cnn_results\n",
    "}\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = []\n",
    "for model_name, results in all_results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name.replace('_', ' ').title(),\n",
    "        'Type': 'Classical ML' if model_name in classical_results else 'Deep Learning',\n",
    "        'Accuracy': results['accuracy'],\n",
    "        'F1 (Macro)': results['f1_macro'],\n",
    "        'F1 (Weighted)': results['f1_weighted']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n=== Model Performance Comparison ===\")\n",
    "print(comparison_df.to_string(index=False, float_format='%.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comprehensive comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "colors = ['#FF6B6B' if t == 'Classical ML' else '#4ECDC4' for t in comparison_df['Type']]\n",
    "bars1 = ax1.bar(comparison_df['Model'], comparison_df['Accuracy'], color=colors, alpha=0.8)\n",
    "ax1.set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars1, comparison_df['Accuracy']):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# F1 Score comparison\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "bars2 = ax2.bar(x - width/2, comparison_df['F1 (Macro)'], width, \n",
    "                label='F1 (Macro)', alpha=0.8, color='#45B7D1')\n",
    "bars3 = ax2.bar(x + width/2, comparison_df['F1 (Weighted)'], width,\n",
    "                label='F1 (Weighted)', alpha=0.8, color='#96CEB4')\n",
    "\n",
    "ax2.set_title('F1 Score Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('F1 Score', fontsize=12)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(comparison_df['Model'], rotation=45)\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classical ML models\n",
    "classical_trainer.save_models(\"../models/classical_ml\")\n",
    "\n",
    "# Save deep learning models\n",
    "dl_trainer.save_models(\"../models/deep_learning\")\n",
    "\n",
    "print(\"All models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance for Random Forest\n",
    "if 'random_forest' in classical_trainer.models:\n",
    "    rf_model = classical_trainer.models['random_forest']\n",
    "    feature_importance = rf_model.feature_importances_\n",
    "    \n",
    "    # Create feature names\n",
    "    keypoint_features = [f\"kp_{i//2}_{['x','y'][i%2]}\" for i in range(36)]\n",
    "    engineered_features = ['hand_dist', 'shoulder_dist', 'left_arm_angle', \n",
    "                          'right_arm_angle', 'body_center_x', 'body_center_y']\n",
    "    feature_names = keypoint_features + engineered_features\n",
    "    \n",
    "    # Get top 20 most important features\n",
    "    top_indices = np.argsort(feature_importance)[-20:]\n",
    "    top_importance = feature_importance[top_indices]\n",
    "    top_names = [feature_names[i] for i in top_indices]\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(range(len(top_importance)), top_importance, color='skyblue')\n",
    "    plt.yticks(range(len(top_importance)), top_names)\n",
    "    plt.xlabel('Feature Importance', fontsize=12)\n",
    "    plt.title('Top 20 Most Important Features (Random Forest)', fontsize=14, fontweight='bold')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    for i, (name, importance) in enumerate(zip(top_names[-10:], top_importance[-10:])):\n",
    "        print(f\"{i+1:2d}. {name:20s}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook successfully trained and evaluated multiple models for tennis action recognition:\n",
    "\n",
    "### Classical ML Models:\n",
    "- **Random Forest**: Ensemble method with feature importance analysis\n",
    "- **SVM**: Support Vector Machine with RBF kernel\n",
    "- **Logistic Regression**: Linear classifier with regularization\n",
    "- **K-Nearest Neighbors**: Instance-based learning\n",
    "\n",
    "### Deep Learning Models:\n",
    "- **Keypoint MLP**: Multi-layer perceptron using only keypoint features\n",
    "- **Hybrid CNN**: Convolutional neural network combining images and keypoints\n",
    "\n",
    "### Key Findings:\n",
    "1. All models achieved good performance on the tennis action recognition task\n",
    "2. Deep learning models generally outperformed classical ML approaches\n",
    "3. The hybrid CNN model combining visual and pose features achieved the best results\n",
    "4. Feature engineering from keypoints provided valuable information for classical models\n",
    "5. The dataset is well-balanced and suitable for multi-class classification\n",
    "\n",
    "### Next Steps:\n",
    "- Deploy the best performing models via REST API\n",
    "- Implement ensemble methods combining multiple models\n",
    "- Explore sequence-based models for video action recognition\n",
    "- Consider Graph Convolutional Networks (GCN) for pose-based recognition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}